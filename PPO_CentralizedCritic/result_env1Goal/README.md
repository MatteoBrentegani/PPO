# PPO with Centralized Critic

# Summary
This code implement a multiple agent version of PPO with centralized critic. In this version there is a single goal for all the agents.

For start the training with this environment just edit the main.py file as follow.

# Code



```
from env1Goal import PPO

```



### performance examples

## Total
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_CentralizedCritic/result_env1Goal/Total.png)
## Agent 1 Reward
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_CentralizedCritic/result_env1Goal/Agent1.png)
## Agent 2 Reward
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_CentralizedCritic/result_env1Goal/Agent1.png)
## Agent 3 Reward
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_CentralizedCritic/result_env1Goal/Agent1.png)
## Agent 4 Reward
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_CentralizedCritic/result_env1Goal/Agent1.png)
