#PPO with double action

### performance examples
#### PPO - Double Action
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_DoubleAction/result/loss_function.png)


#### PPO - Double Action with obstacle
![image](https://github.com/MatteoBrentegani/PPO/blob/master/PPO_DoubleAction/result/loss_function_withObstable.png)
